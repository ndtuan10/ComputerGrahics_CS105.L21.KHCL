{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af143ce5-2d2b-4daa-9f9a-56964d60c491",
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "from PIL import Image, ImageDraw\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6d1ef3a-be91-48c0-9e0f-bfec22b9552b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = face_recognition.load_image_file(\"image/001.jpg\")\n",
    "face_locations = face_recognition.face_locations(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7e88d1a-92b3-4f0c-ae24-70ed747ada56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resized Dimensions :  (2400, 3600, 3)\n"
     ]
    }
   ],
   "source": [
    "scale_percent = 60 # percent of original size\n",
    "width = int(image.shape[1] * scale_percent / 100)\n",
    "height = int(image.shape[0] * scale_percent / 100)\n",
    "dim = (width, height)\n",
    "  \n",
    "# resize image\n",
    "resized = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\n",
    " \n",
    "print('Resized Dimensions : ',resized.shape)\n",
    " \n",
    "cv2.imshow(\"Resized image\", resized)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c73ad8e5-d87d-45e1-8d5d-59db9bb3f6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I found1 face(s) in this photograph.\n",
      "The chin in this face has the following points: [(1375, 970), (1369, 1068), (1372, 1171), (1388, 1274), (1422, 1369), (1482, 1451), (1558, 1520), (1644, 1571), (1745, 1586), (1844, 1576), (1935, 1530), (2019, 1473), (2084, 1401), (2127, 1317), (2151, 1221), (2165, 1121), (2173, 1024)]\n",
      "The left_eyebrow in this face has the following points: [(1438, 909), (1491, 848), (1573, 836), (1653, 860), (1729, 895)]\n",
      "The right_eyebrow in this face has the following points: [(1819, 901), (1893, 873), (1974, 860), (2054, 879), (2100, 944)]\n",
      "The nose_bridge in this face has the following points: [(1770, 967), (1764, 1029), (1759, 1088), (1753, 1151)]\n",
      "The nose_tip in this face has the following points: [(1661, 1199), (1704, 1208), (1751, 1220), (1798, 1212), (1849, 1206)]\n",
      "The left_eye in this face has the following points: [(1532, 961), (1575, 943), (1621, 948), (1663, 980), (1617, 979), (1569, 974)]\n",
      "The right_eye in this face has the following points: [(1877, 994), (1918, 970), (1962, 973), (2003, 994), (1963, 1002), (1917, 1001)]\n",
      "The top_lip in this face has the following points: [(1582, 1283), (1646, 1271), (1705, 1264), (1751, 1277), (1799, 1268), (1863, 1280), (1928, 1302), (1908, 1302), (1799, 1294), (1750, 1298), (1704, 1291), (1603, 1287)]\n",
      "The bottom_lip in this face has the following points: [(1928, 1302), (1862, 1333), (1800, 1347), (1750, 1349), (1701, 1342), (1645, 1323), (1582, 1283), (1603, 1287), (1704, 1301), (1751, 1309), (1800, 1307), (1908, 1302)]\n"
     ]
    }
   ],
   "source": [
    "# face landmarks\n",
    "face_landmarks_list = face_recognition.face_landmarks(resized)\n",
    "\n",
    "print(\"I found{} face(s) in this photograph.\".format(len(face_landmarks_list)))\n",
    "\n",
    "#Create a PIL imagedraw object so we can draw on the picture\n",
    "pil_image = Image.fromarray(resized)\n",
    "d = ImageDraw.Draw(pil_image)\n",
    "\n",
    "for face_landmarks in face_landmarks_list:\n",
    "    # Print the location of each facial feature in this image\n",
    "    for facial_feature in face_landmarks.keys():\n",
    "        print(\"The {} in this face has the following points: {}\".format(facial_feature, face_landmarks[facial_feature]))\n",
    "        \n",
    "    # Let's trace out each facial feature in the image with a line!\n",
    "    for facial_feature in face_landmarks.keys():\n",
    "        d.line(face_landmarks[facial_feature], width=5)\n",
    "        \n",
    "#Show the picture\n",
    "pil_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8b460d9-0e4a-4c42-9210-82242d18a135",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Face recognition\n",
    "# To capture video from webcam. \n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "# To use a video file as input \n",
    "#cap = cv2.VideoCapture(\".../filename.mp4\")\n",
    "\n",
    "#Load a sample picture and learn how to recognize it.\n",
    "T_image = face_recognition.load_image_file(\"image/001.jpg\")\n",
    "T_face_encoding = face_recognition.face_encodings(T_image)[0]\n",
    "\n",
    "#Create arrays of known face encodings and their names\n",
    "known_face_encodings = [\n",
    "    T_face_encoding,\n",
    "]\n",
    "\n",
    "known_face_names = [\n",
    "    \"Tuan\",\n",
    "]\n",
    "\n",
    "while True:\n",
    "    #Grab a single frame of video\n",
    "    ret,frame = video_capture.read()\n",
    "    \n",
    "    #Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses)\n",
    "    rgb_frame = frame[:,:,::-1]\n",
    "    \n",
    "    #Find all the faces and face encodings in the frame of video\n",
    "    face_locations = face_recognition.face_locations(rgb_frame)\n",
    "    face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "    \n",
    "    #Loop through each face in this frame of video\n",
    "    for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "        #See if the face is a match for the known face(s)\n",
    "        matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "        \n",
    "        name = \"Unknown\"\n",
    "        \n",
    "        #If a match was found in known_face_encodings, just use the first one\n",
    "        #if True in matches:\n",
    "        #  first_match_index = matches.index(True)\n",
    "        #  name = known_face_names[first_match_index]\n",
    "        \n",
    "        #Or instead, use the known face with the smallest distance to the new face\n",
    "        face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "        best_match_index = np.argmin(face_distances)\n",
    "        if matches[best_match_index]:\n",
    "            name = known_face_names[best_match_index]\n",
    "        \n",
    "        #Draw a box around the face\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0,0,255),2)\n",
    "        \n",
    "        #Draw a label with a name below the face\n",
    "        cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0,0,255), cv2.FILLED)\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        cv2.putText(frame, name, (left + 6, bottom -6), font, 1.0, (255,255,255),1)\n",
    "    \n",
    "    #Display the resulting image\n",
    "    cv2.imshow('video', frame)\n",
    "    \n",
    "    #Hit 'q' on the keyboard to quit!\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "#Release handle to the webcam\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
